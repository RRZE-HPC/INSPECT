{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import html\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import compress_pickle\n",
    "\n",
    "from hpc_inspect.inspector import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = compress_pickle.load('dataframe.pickle.lzma')\n",
    "#data.set_index(['pmodel', 'compiler', 'incore_model', 'cores', 'define'], inplace=True)\n",
    "compilers = [cc for cc in data.compiler.unique() if cc is not None]\n",
    "incore_models = [icm for icm in data.incore_model.unique() if icm is not None]\n",
    "cache_predictors = [cp for cp in data.cache_predictor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stencil Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO present origin and property of kernel code\n",
    "iterations_per_cacheline = int(data.get('iterations per cacheline').dropna().unique()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.iloc[0].job.workload.kernel.get_code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Core Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get analysis alongside with assembly for each compiler and in-core model\n",
    "cc_tab = widgets.Tab()\n",
    "cc_tab_children = []\n",
    "for i, cc in enumerate(compilers):\n",
    "    cc_tab.set_title(i, cc)\n",
    "    icm_tab = widgets.Tab(children=[])\n",
    "    icm_tab_children = []\n",
    "    cc_tab_children.append(icm_tab)\n",
    "    for j, icm in enumerate(incore_models):\n",
    "        icm_tab.set_title(j, icm)\n",
    "        icm_tab_children.append(\n",
    "            widgets.HTML(value='<pre style=\"line-height: 1;\">{}</pre>'.format(html.escape(\n",
    "                data.query(\"compiler == @cc and incore_model == @icm\")['in-core model output'].unique()[0]))))\n",
    "    icm_tab.children = icm_tab_children\n",
    "cc_tab.children = cc_tab_children\n",
    "\n",
    "cc_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO readout and present LCs\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Core Grid Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECM Prediction vs Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_defines = data.sort_values(by=['define'])\n",
    "fig, axs = mpl.pyplot.subplots(len(compilers), len(incore_models), squeeze=False,\n",
    "                               figsize=(7*len(incore_models),4*len(compilers)))\n",
    "for i_cc, cc in enumerate(compilers):\n",
    "    for i_icm, icm in enumerate(incore_models):\n",
    "        ax = axs[i_cc, i_icm]\n",
    "        ax.set_title(\"{} {}\".format(cc, icm))\n",
    "        ax.set_ylabel(\"cycle per {} iterations\".format(iterations_per_cacheline))\n",
    "        ax.set_xlabel(\"\")\n",
    "        ecm_data = data_defines.query('pmodel==\"ECM\" and cores==1 and incore_model == @icm')\n",
    "        ecm_data.plot.area(\n",
    "            y=['T_RegL1', 'T_L1L2', 'T_L2L3', 'T_L3MEM'], x='define', logx=True, xlim=100, ylim=0, ax=ax)\n",
    "        data_defines.query('pmodel==\"Benchmark\" and cores==1').plot(\n",
    "            y='performance [cy/CL]', x='define', logx=True, xlim=100, ylim=0, label='Measured', ax=ax)\n",
    "        data_defines.query('pmodel==\"RooflineIACA\" and incore_model == @icm').plot(\n",
    "            y='performance [cy/CL]', x='define', logx=True, xlim=100, ylim=0, label='RL pred.', ax=ax)\n",
    "# TODO improve legend (and reduce to one)\n",
    "# TODO name columns and rows\n",
    "# TODO fix scale/limits to show all available data\n",
    "# TODO add It/s, flop/s axis to right\n",
    "# TODO find good metric (or name) for x-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cp in cache_predictors:\n",
    "    data.query('cache_predictor==@cp')\n",
    "\n",
    "# TODO include predicted information into pandas\n",
    "# TODO include measured informatin into pandas (inspector.py:574)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Core Thread Sacling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cores = data.sort_values(by=['cores'])\n",
    "fig, axs = mpl.pyplot.subplots(len(compilers), len(incore_models), squeeze=False,\n",
    "                               figsize=(7*len(incore_models),4*len(compilers)))\n",
    "max_define = data.define.max()\n",
    "for i_cc, cc in enumerate(compilers):\n",
    "    for i_icm, icm in enumerate(incore_models):\n",
    "        ax = axs[i_cc, i_icm]\n",
    "        ax.set_title(\"{} {}\".format(cc, icm))\n",
    "        data_cores.query('pmodel==\"Benchmark\" and define==@max_define').plot(\n",
    "            x='cores', y='performance [cy/CL]', xlim=1, ylim=0, legend=True, label='Measured', ax=ax)\n",
    "        data_cores.query('pmodel==\"ECM\" and define==@max_define and incore_model==@icm').plot(\n",
    "            x='cores', y='performance [cy/CL]', xlim=1, ylim=0, legend=True, label='ECM pred.', ax=ax)\n",
    "        data_cores.query('pmodel==\"RooflineIACA\" and define==@max_define and incore_model==@icm').plot(\n",
    "            x='cores', y='performance [cy/CL]', xlim=1, ylim=0, legend=True, label='RL pred.', ax=ax)\n",
    "        ax.set_xticks(range(int(data.cores.min()), int(data.cores.max() + 1)))\n",
    "# TODO find issue with ECM scaling curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO collect and present machine state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook things to look at:\n",
    " * https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Styling.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('python37': virtualenv)",
   "language": "python",
   "name": "python37564bitpython37virtualenve45cc6d57f8c49279c8350752a82a235"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
