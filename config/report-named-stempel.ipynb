{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"svg\"\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "from kerncraft.machinemodel import MachineModel\n",
    "from kerncraft.kernel import KernelCode\n",
    "\n",
    "from hpc_inspect.inspector import *\n",
    "from hpc_inspect.report_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "machine = MachineModel(path_to_yaml='machine.yml')\n",
    "kernel = KernelCode(Path('kernel.c').read_text(), machine)\n",
    "print('model name:', machine['model name'])\n",
    "print('frequency:', machine['clock'])\n",
    "print(os.getcwd().split('jobs/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = load_pickled_dataframe()\n",
    "compilers = get_unique(data, 'compiler')\n",
    "incore_models = get_unique(data, 'incore_model')\n",
    "cache_predictors = get_unique(data, 'cache_predictor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Stencil Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# TODO present origin and property of kernel code\n",
    "iterations_per_cacheline = get_iterations_per_cacheline(data)\n",
    "print(\"Iterations per cacheline (unrolling and SIMD considered):\", iterations_per_cacheline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Kernel Source Code\n",
    "The C representation of the kernel, as it was passed to Kerncraft for anlysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "Code(data.iloc[0].job.workload.kernel.get_code(), language='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### In-Core Analysis\n",
    "For each compiler and in-core analysis model/application, the output is presented below. The analyzed assembly is the same per compiler, but outputs may differ as IACA analyzes bytecode and prints in Intel syntax, where as OSACA and LLVM-MCA use the original assembly for output.\n",
    "Also note, that the resulting cycle counts need to be scaled accourding the highlevel iterations. The compiler may have unrolled or vectorized the code an thus folded multiple high-level iterations into this single assembly block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc_tab = widgets.Tab()\n",
    "cc_tab_children = []\n",
    "for i, cc in enumerate(compilers):\n",
    "    cc_tab.set_title(i, cc)\n",
    "    icm_tab = widgets.Tab(children=[])\n",
    "    icm_tab_children = []\n",
    "    cc_tab_children.append(icm_tab)\n",
    "    for j, icm in enumerate(incore_models):\n",
    "        icm_tab.set_title(j, icm)\n",
    "        model_output = list(data.query(\"compiler == @cc and incore_model == @icm\")['in-core model output'].iloc(0))\n",
    "        if model_output:\n",
    "            model_output = model_output[0]\n",
    "        else:\n",
    "            model_output = ''\n",
    "        icm_tab_children.append(\n",
    "            widgets.HTML(value='<pre style=\"line-height: 1; white-space: pre !important;\">{}</pre>'.format(html.escape(model_output))))\n",
    "    icm_tab.children = icm_tab_children\n",
    "cc_tab.children = cc_tab_children\n",
    "display(cc_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Layer Conditions\n",
    "A general explaination of Layer Conditions (LC) can be found at https://rrze-hpc.github.io/layer-condition. These conditions assume inclusive least-recently-used caches, ignoring associativity effects.\n",
    "\n",
    "Each row is one LC, if the condition holds, one may assume the number of hits and misses observed on the cache level and evicts going out of this level. If the condition is simply \"True\" it is the fallback streaming case, where almost no reuse can be served out of this cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# TODO present size of N for condition to be fullfilled\n",
    "\n",
    "lc_data = []\n",
    "for col in data.columns:\n",
    "    if not col.endswith(' LCs'):\n",
    "        continue\n",
    "    cache = col.split(' ')[0]\n",
    "    for lc in data.get(col).dropna()[0]:\n",
    "        lc['cache'] = cache\n",
    "        lc_data.append(lc)\n",
    "lc_df = pd.DataFrame(lc_data)\n",
    "if not lc_df.empty:\n",
    "    idx = pd.MultiIndex.from_frame(lc_df[['cache', 'tail']])\n",
    "    lc_df = pd.DataFrame(lc_data, columns=['condition', 'hits', 'misses', 'evicts'], index=idx)\n",
    "    display(lc_df)\n",
    "    display(HTML(\"<p>hits, misses and evicts are given in number of elements</p>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Single Core Grid Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Model Prediction vs Performance\n",
    "Comparing ECM and Roofline model predictions with measured performance data, in relation to the dimension size. The right-hand axis presenting \"giga iterations per second\" is an inverse of cycles per iteration and therefore a logarithmic scale. The x-axis is the dimension length for all dimensions variables in the code (e.g., if a code has an array `a[3][N][2*M]`, a dimension length of 1024 will result in `a[3][1024][2048]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO find good metric (or name) for x-axis\n",
    "# TODO highlight T_comp\n",
    "\n",
    "# Extract overlapping and non-overlapping data-transfer components from\n",
    "# machine mokdel definition\n",
    "overlapping_ecm_transfers = [\n",
    "    'T_{}{}'.format(from_['level'], to['level'])\n",
    "    for from_, to in zip([{'level': 'Reg'}] + machine['memory hierarchy'][:-1],\n",
    "                         machine['memory hierarchy'])\n",
    "    if to['transfers overlap']]\n",
    "nonoverlapping_ecm_transfers = [\n",
    "    'T_{}{}'.format(from_['level'], to['level'])\n",
    "    for from_, to in zip([{'level': 'Reg'}] + machine['memory hierarchy'][:-1],\n",
    "                         machine['memory hierarchy'])\n",
    "    if not to['transfers overlap']]\n",
    "plt.ioff()\n",
    "cp_tab = widgets.Tab()\n",
    "cp_tab_children = []\n",
    "for i, cp in enumerate(cache_predictors):\n",
    "    cp_tab.set_title(i, cp)\n",
    "    data_defines = data.sort_values(by=['define'])\n",
    "    if compilers and incore_models:\n",
    "        fig, axs = plt.subplots(len(compilers), len(incore_models),\n",
    "                                squeeze=False,\n",
    "                                figsize=(4*len(incore_models),3*len(compilers)),\n",
    "                                sharey=True,\n",
    "                                sharex=True)\n",
    "        fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    ylimit = np.nanmax([\n",
    "        data_defines.query(\n",
    "            'pmodel==\"RooflineIACA\" and cores==1 and define > define.max()*0.9 and '\n",
    "            'cache_predictor == @cp')['performance [cy/CL]'].mean(skipna=True),\n",
    "        data_defines.query(\n",
    "            'pmodel==\"ECM\" and cores==1 and define > define.max()*0.9 and '\n",
    "            'cache_predictor == @cp')['performance [cy/CL]'].mean(skipna=True),\n",
    "        data_defines.query(\n",
    "            'pmodel==\"Benchmark\" and cores==1')['performance [cy/CL]'].max(skipna=True)])\n",
    "\n",
    "    for i_cc, cc in enumerate(compilers):\n",
    "        for i_icm, icm in enumerate(incore_models):\n",
    "            ax = axs[i_cc, i_icm]\n",
    "            ax.set_title(\"{} {}\".format(cc, icm))\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_ylim(0, ylimit*1.05)\n",
    "            ax.xaxis.set_tick_params(labelbottom=True)\n",
    "            #ax.yaxis.set_tick_params(labelleft=True)\n",
    "            ax.grid()\n",
    "            ax.set_axisbelow(True)  # places gridlines behind everything else\n",
    "\n",
    "            # ECM\n",
    "            ecm_data = data_defines.query(\n",
    "                'pmodel==\"ECM\" and cores==1 and incore_model == @icm and '\n",
    "                'compiler == @cc and cache_predictor == @cp')\n",
    "            ax.stackplot(\n",
    "                ecm_data['define'],\n",
    "                *[ecm_data[t] for t in nonoverlapping_ecm_transfers],\n",
    "                labels=[t for t in nonoverlapping_ecm_transfers])\n",
    "            ax.plot(ecm_data['define'], ecm_data.T_comp, label='T_comp')\n",
    "            for t in overlapping_ecm_transfers:\n",
    "                ax.plot(ecm_data['define'], ecm_data[t], label=t)\n",
    "\n",
    "            # Benchmark\n",
    "            bench_data = data_defines.query('pmodel==\"Benchmark\" and cores==1 and compiler == @cc and cores==1')\n",
    "            ax.plot(bench_data.define, bench_data['performance [cy/CL]'], '+', label='Measured')\n",
    "\n",
    "            # RooflineIACA\n",
    "            roof_data = data_defines.query('pmodel==\"RooflineIACA\" and incore_model == @icm and '\n",
    "                                           'compiler == @cc and cache_predictor == @cp and cores==1')\n",
    "            ax.plot(roof_data.define, roof_data['performance [cy/CL]'], label='RL pred.')\n",
    "\n",
    "            ax.set_ylim(0)\n",
    "            if i_icm == len(incore_models) - 1:\n",
    "                T_to_P = lambda T: divide(float(machine['clock']), T) * iterations_per_cacheline\n",
    "                ax_right = ax.twinx()\n",
    "                ymin, ymax = ax.get_ylim()\n",
    "                yticks = ax.get_yticks().tolist()\n",
    "                ax_right.set_ylim(ax.get_ylim())\n",
    "                ax_right.yaxis.set_major_locator(mticker.FixedLocator(yticks))\n",
    "                ax.yaxis.set_major_locator(mticker.FixedLocator(yticks))\n",
    "                with np.errstate(divide='ignore'):\n",
    "                    yticks_its = [T_to_P(t) for t in yticks]\n",
    "                if max([its for its in yticks_its if its < float('inf')]) > 5*1e8:\n",
    "                    its_factor, its_factor_name = 1e9, \"giga\"\n",
    "                elif max([its for its in yticks_its if its < float('inf')]) > 5*1e5:\n",
    "                    its_factor, its_factor_name = 1e6, \"mega\"\n",
    "                elif max([its for its in yticks_its if its < float('inf')]) > 5*1e2:\n",
    "                    its_factor, its_factor_name = 1e3, \"kilo\"\n",
    "                else:\n",
    "                    its_factor, its_factor_name = 1, \"\"\n",
    "                ax_right.set_yticklabels([\"{:.2f}\".format(t/its_factor) for t in yticks_its])\n",
    "                ax_right.set_ylabel(\"{} iterations per second\".format(its_factor_name))\n",
    "            if i_icm == 0 and i_cc == 0:\n",
    "                ax.legend(bbox_to_anchor=(0.5, 0.0), ncol=len(incore_models)*3,\n",
    "                          loc='lower center', bbox_transform=fig.transFigure)\n",
    "            if i_icm == 0:\n",
    "                ax.set_ylabel(\"cycle per {} iterations\".format(iterations_per_cacheline))\n",
    "            if i_cc == len(compilers) - 1:\n",
    "                ax.set_xlabel(\"dimension length\")\n",
    "    if len(incore_models) == 1:  # only one column\n",
    "        fig.subplots_adjust(right=0.85)  # otherwise twinx will be partially hidden\n",
    "    f = io.BytesIO()\n",
    "    fig.savefig(f, format=\"svg\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    cp_tab_children.append(widgets.HTML(value=f.getvalue()))\n",
    "cp_tab.children = cp_tab_children\n",
    "plt.ion()\n",
    "display(cp_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": false
   },
   "source": [
    "### Data Transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "for cp in cache_predictors:\n",
    "    data.query('cache_predictor==@cp')\n",
    "\n",
    "# TODO include predicted information into pandas\n",
    "# TODO include measured informatin into pandas (inspector.py:574)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Multi-core Thread Sacling\n",
    "Scaling of OpenMP parallelized kernel, with tight placement (e.g., NUMA domains are filled up one after another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#display(get_scaling_tabs(data, machine))\n",
    "\n",
    "plt.ioff()\n",
    "cp_tab = widgets.Tab()\n",
    "cp_tab_children = []\n",
    "for i, cp in enumerate(cache_predictors):\n",
    "    cp_tab.set_title(i, cp)\n",
    "    if compilers and incore_models:\n",
    "        fig, axs = plt.subplots(len(compilers), len(incore_models), squeeze=False,\n",
    "                                figsize=(4*len(incore_models),3*len(compilers)),\n",
    "                                sharey=True,\n",
    "                                sharex=True)\n",
    "        fig.subplots_adjust(hspace=0.3)\n",
    "    max_define = data.define.max()\n",
    "    for i_cc, cc in enumerate(compilers):\n",
    "        for i_icm, icm in enumerate(incore_models):\n",
    "            ax = axs[i_cc, i_icm]\n",
    "            ax.set_title(\"{} {}\".format(cc, icm))\n",
    "            ax.xaxis.set_tick_params(labelbottom=True)\n",
    "            ax.grid()\n",
    "\n",
    "            bench_data = data.query(\n",
    "                'pmodel==\"Benchmark\" and define==@max_define and compiler == @cc'\n",
    "            ).sort_values(by=['cores'])\n",
    "            ax.plot(bench_data.cores, bench_data['performance [It/s]']/1e9, label='Measured')\n",
    "            ecm_data = data.query(\n",
    "                'pmodel==\"ECM\" and define==@max_define and incore_model==@icm and '\n",
    "                'compiler == @cc and cache_predictor == @cp'\n",
    "            ).sort_values(by=['cores'])\n",
    "            ax.plot(ecm_data.cores, ecm_data['performance [It/s]']/1e9, label='ECM pred.')\n",
    "            roof_data = data.query(\n",
    "                'pmodel==\"RooflineIACA\" and define==@max_define and incore_model==@icm and '\n",
    "                'compiler == @cc and cache_predictor == @cp'\n",
    "            ).sort_values(by=['cores'])\n",
    "            ax.plot(roof_data.cores, roof_data['performance [It/s]']/1e9, label='RL pred.')\n",
    "\n",
    "            ax.set_ylim(0)\n",
    "            ax.set_axisbelow(True)  # places gridlines behind everything else\n",
    "            if i_icm != 0:\n",
    "                ax.yaxis.set_tick_params(labelleft=False)\n",
    "            if i_icm == len(incore_models) - 1:\n",
    "                P_to_T = lambda P: iterations_per_cacheline*divide(float(machine['clock']), P)\n",
    "                ax_right = ax.twinx()\n",
    "                ymin, ymax = ax.get_ylim()\n",
    "                ax_right.set_ylim(ax.get_ylim())\n",
    "                yticks = ax.get_yticks().tolist()\n",
    "                ax.yaxis.set_major_locator(mticker.FixedLocator(yticks))\n",
    "                ax_right.yaxis.set_major_locator(mticker.FixedLocator(yticks))\n",
    "                with np.errstate(divide='ignore'):\n",
    "                    ax_right.set_yticklabels([\"{:.2f}\".format(P_to_T(t*1e9))\n",
    "                                              for t in yticks])\n",
    "                ax_right.set_ylabel(\"cycle per {} iterations\".format(iterations_per_cacheline))\n",
    "            # use default ticks, but always start at min_cores and end at max_cores\n",
    "            min_cores, max_cores = int(data.cores.min()), int(data.cores.max())\n",
    "            ax.set_xticks([t for t in ax.get_xticks()\n",
    "                           if min_cores < t < max_cores] +\n",
    "                          [min_cores, max_cores])\n",
    "            #ax.minorticks_on()\n",
    "            if i_icm == 0 and i_cc == 0:\n",
    "                ax.legend(bbox_to_anchor=(0.5, 0.0), ncol=len(incore_models)*3,\n",
    "                          loc='lower center', bbox_transform=fig.transFigure)\n",
    "            if i_icm == 0:\n",
    "                ax.set_ylabel(\"giga iterations per second\")\n",
    "            if i_cc == len(compilers) - 1:\n",
    "                ax.set_xlabel(\"cores\")\n",
    "    if len(incore_models) == 1:  # only one column\n",
    "        fig.subplots_adjust(right=0.85)  # otherwise twinx will be partially hidden\n",
    "    f = io.BytesIO()\n",
    "    fig.savefig(f, format=\"svg\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    cp_tab_children.append(widgets.HTML(\n",
    "        value=f.getvalue()+\"<p>with dimension length = {}</p>\".format(int(max_define)).encode('utf8')))\n",
    "cp_tab.children = cp_tab_children\n",
    "plt.ion()\n",
    "display(cp_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('machinestate.json') as f:\n",
    "        ms_data = json.load(f)\n",
    "        ms = machinestate.MachineState.from_dict(ms_data)\n",
    "        display(HTML(ms.get_html()))\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(\"Unable to load or process machinestate. Usually a version discrepancy.\")\n",
    "    traceback.print_exc()\n",
    "# TODO replace by more elegent solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('python37': virtualenv)",
   "language": "python",
   "name": "python37564bitpython37virtualenve45cc6d57f8c49279c8350752a82a235"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
